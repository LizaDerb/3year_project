{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9b74b6-57ef-4f66-af01-1c54c2fd1476",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Скачивание и предобработка текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e946a-0ce8-427b-b843-1645730b4f82",
   "metadata": {},
   "source": [
    "Скачаем тексты сочинений с сайта https://mogu-pisat.ru/sochinenie/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9ac3b3-3188-4822-9ac8-d9281f8d4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360621c5-d7e5-427f-a043-258842cdbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b151125-2c12-4f39-8938-8e5d511b8752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\python_for_nlp_stud\\venv\\lib\\site-packages (6.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: ua-parser in c:\\python_for_nlp_stud\\venv\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: user-agents in c:\\python_for_nlp_stud\\venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\python_for_nlp_stud\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\python_for_nlp_stud\\venv\\lib\\site-packages (from fake-useragent) (5.10.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\python_for_nlp_stud\\venv\\lib\\site-packages (from importlib-resources>=5.0->fake-useragent) (3.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml ua-parser user-agents fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3134af98-0d12-4ee9-a89f-ef1bc83ae284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2bfd5f-ea83-473c-a4ea-4fff5b18ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:33:40.491902\n",
      "2023-10-22 14:33:41.850710\n",
      "2023-10-22 14:33:43.169226\n",
      "2023-10-22 14:33:44.528347\n",
      "2023-10-22 14:33:45.841383\n",
      "2023-10-22 14:33:47.209081\n",
      "2023-10-22 14:33:48.580162\n",
      "2023-10-22 14:33:49.899040\n",
      "2023-10-22 14:33:51.265259\n",
      "2023-10-22 14:33:52.632501\n",
      "2023-10-22 14:33:53.982938\n",
      "2023-10-22 14:33:55.311603\n",
      "2023-10-22 14:33:56.629549\n",
      "2023-10-22 14:33:57.941310\n",
      "2023-10-22 14:33:59.260338\n",
      "2023-10-22 14:34:00.577962\n",
      "2023-10-22 14:34:01.957523\n",
      "2023-10-22 14:34:03.323548\n",
      "2023-10-22 14:34:04.689071\n",
      "2023-10-22 14:34:06.008837\n",
      "2023-10-22 14:34:07.401841\n",
      "2023-10-22 14:34:08.763402\n",
      "2023-10-22 14:34:10.122616\n",
      "2023-10-22 14:34:11.503377\n",
      "2023-10-22 14:34:12.825042\n",
      "2023-10-22 14:34:14.137947\n",
      "2023-10-22 14:34:15.516461\n",
      "2023-10-22 14:34:16.858599\n",
      "2023-10-22 14:34:18.227130\n",
      "2023-10-22 14:34:19.614720\n",
      "2023-10-22 14:34:21.020286\n",
      "2023-10-22 14:34:22.407643\n",
      "2023-10-22 14:34:23.729650\n",
      "2023-10-22 14:34:25.085689\n",
      "2023-10-22 14:34:26.403696\n",
      "2023-10-22 14:34:27.764930\n",
      "2023-10-22 14:34:29.084216\n",
      "2023-10-22 14:34:30.398838\n",
      "2023-10-22 14:34:31.717005\n",
      "2023-10-22 14:34:33.068247\n",
      "2023-10-22 14:34:34.379924\n",
      "2023-10-22 14:34:35.703848\n",
      "2023-10-22 14:34:37.062120\n",
      "2023-10-22 14:34:38.436940\n",
      "2023-10-22 14:34:39.754807\n",
      "2023-10-22 14:34:41.100673\n",
      "2023-10-22 14:34:42.469141\n",
      "2023-10-22 14:34:43.844377\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "\n",
    "for n in range(2, 50):\n",
    "    link = 'https://mogu-pisat.ru/sochinenie/ege/?PAGEN_1={}'.format(n)\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    response = session.get(link, headers=headers).text\n",
    "    pages.append(response)\n",
    "    print(datetime.now())\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8819a1c4-4b58-43be-8784-1608353b372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d13fd2-4e80-43d4-9075-a12a2fe34fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for page in pages:\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    new_links = soup.find_all('div', {'class' : \"b-news-item-name\"})\n",
    "    for i in new_links:\n",
    "        one = i.find('a').get('href')\n",
    "        links.append(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84cf52a9-fe37-48a5-946c-011351bd3500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed7eb2d-16d8-4dbd-a5e7-29d0162e0b29",
   "metadata": {},
   "source": [
    "С помощью краулинга мы собрали ссылки на 960 сочинений. Учитывая, что размер сочинений, как правило, составляет около 200 слов, скачаем 90 сочинений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35267119-c42b-4e1a-967e-309ce4293c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-22 14:39:30.625743\n",
      "2023-10-22 14:39:31.912861\n",
      "2023-10-22 14:39:33.149899\n",
      "2023-10-22 14:39:34.405091\n",
      "2023-10-22 14:39:35.695579\n",
      "2023-10-22 14:39:36.913652\n",
      "2023-10-22 14:39:38.469564\n",
      "2023-10-22 14:39:39.760471\n",
      "2023-10-22 14:39:41.018930\n",
      "2023-10-22 14:39:42.266418\n",
      "2023-10-22 14:39:43.543801\n",
      "2023-10-22 14:39:44.782256\n",
      "2023-10-22 14:39:46.079700\n",
      "2023-10-22 14:39:47.368269\n",
      "2023-10-22 14:39:48.619841\n",
      "2023-10-22 14:39:49.862448\n",
      "2023-10-22 14:39:51.149636\n",
      "2023-10-22 14:39:52.402537\n",
      "2023-10-22 14:39:53.680204\n",
      "2023-10-22 14:39:54.932063\n",
      "2023-10-22 14:39:56.364497\n",
      "2023-10-22 14:39:57.893346\n",
      "2023-10-22 14:39:59.214480\n",
      "2023-10-22 14:40:00.517411\n",
      "2023-10-22 14:40:01.753321\n",
      "2023-10-22 14:40:02.992797\n",
      "2023-10-22 14:40:04.319028\n",
      "2023-10-22 14:40:05.559746\n",
      "2023-10-22 14:40:06.813549\n",
      "2023-10-22 14:40:08.099768\n",
      "2023-10-22 14:40:09.391995\n",
      "2023-10-22 14:40:10.727886\n",
      "2023-10-22 14:40:12.003827\n",
      "2023-10-22 14:40:13.255667\n",
      "2023-10-22 14:40:14.525179\n",
      "2023-10-22 14:40:15.823203\n",
      "2023-10-22 14:40:17.112650\n",
      "2023-10-22 14:40:18.367673\n",
      "2023-10-22 14:40:19.642352\n",
      "2023-10-22 14:40:20.983507\n",
      "2023-10-22 14:40:22.272500\n",
      "2023-10-22 14:40:23.651969\n",
      "2023-10-22 14:40:24.907016\n",
      "2023-10-22 14:40:26.244048\n",
      "2023-10-22 14:40:27.476342\n",
      "2023-10-22 14:40:28.898481\n",
      "2023-10-22 14:40:30.143723\n",
      "2023-10-22 14:40:31.516400\n",
      "2023-10-22 14:40:32.821593\n",
      "2023-10-22 14:40:34.214997\n",
      "2023-10-22 14:40:35.560659\n",
      "2023-10-22 14:40:36.860274\n",
      "2023-10-22 14:40:38.165094\n",
      "2023-10-22 14:40:39.483637\n",
      "2023-10-22 14:40:40.710516\n",
      "2023-10-22 14:40:41.979538\n",
      "2023-10-22 14:40:43.304251\n",
      "2023-10-22 14:40:44.558045\n",
      "2023-10-22 14:40:45.875891\n",
      "2023-10-22 14:40:47.164686\n",
      "2023-10-22 14:40:48.424681\n",
      "2023-10-22 14:40:49.691990\n",
      "2023-10-22 14:40:50.966867\n",
      "2023-10-22 14:40:52.189467\n",
      "2023-10-22 14:40:53.447378\n",
      "2023-10-22 14:40:54.717267\n",
      "2023-10-22 14:40:55.963451\n",
      "2023-10-22 14:40:57.268465\n",
      "2023-10-22 14:40:58.610717\n",
      "2023-10-22 14:40:59.862981\n",
      "2023-10-22 14:41:01.371784\n",
      "2023-10-22 14:41:02.693638\n",
      "2023-10-22 14:41:03.937947\n",
      "2023-10-22 14:41:05.207269\n",
      "2023-10-22 14:41:06.451214\n",
      "2023-10-22 14:41:07.704923\n",
      "2023-10-22 14:41:08.943729\n",
      "2023-10-22 14:41:10.245584\n",
      "2023-10-22 14:41:11.473363\n",
      "2023-10-22 14:41:12.782333\n",
      "2023-10-22 14:41:14.037289\n",
      "2023-10-22 14:41:15.328025\n",
      "2023-10-22 14:41:16.631361\n",
      "2023-10-22 14:41:17.921754\n",
      "2023-10-22 14:41:19.160368\n",
      "2023-10-22 14:41:20.435984\n",
      "2023-10-22 14:41:21.689288\n",
      "2023-10-22 14:41:22.946607\n",
      "2023-10-22 14:41:24.199621\n",
      "2023-10-22 14:41:25.490345\n"
     ]
    }
   ],
   "source": [
    "essays = dict()\n",
    "ids = 0\n",
    "\n",
    "for l in links[:90]:\n",
    "    full_link = 'https://mogu-pisat.ru' + l\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    response = session.get(full_link, headers=headers).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    text = soup.find('div', {\"style\" : \"font-size:17px;\"}).get_text()\n",
    "    title = soup.title.get_text()\n",
    "    author = soup.find_all('div', {\"style\" : \"font-size:16px;\"})[1].get_text()\n",
    "    data = [text, title, author, full_link]\n",
    "    essays.update({ids : data})\n",
    "    ids += 1\n",
    "    print(datetime.now())\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5fec2c3-d684-4393-99e9-60cc0fd2f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3bbb3-3e73-4187-9f2a-460b47954cae",
   "metadata": {},
   "source": [
    "Essays - словарь, в котором ключами являются id сочинений, а значениями - информация о них: \n",
    "1. текст сочинения\n",
    "2. название сочинения\n",
    "3. автор\n",
    "4. ссылка на сайт"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3607d-291f-4e30-a025-3a897b2c33ff",
   "metadata": {},
   "source": [
    "Сохраним получившийся корпус в файл формата json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b4650d-c9fa-4f74-b3d3-04d37ec18ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('corpus.json', 'w', encoding=\"utf-8\") as fp:\n",
    "    json.dump(essays, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a190a68-73e7-43fc-96ed-0e2966537f14",
   "metadata": {},
   "source": [
    "Разделим сочинения на предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a0fefa8-865d-4546-b93c-561f3d77a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "def cleaning(text):\n",
    "    cleaning = \"\\n\\xa0«»\\t—…\" + \"'‘’\"\n",
    "    new_text = ''\n",
    "\n",
    "    for ch in text:\n",
    "        if ch not in cleaning:\n",
    "            new_text += ch\n",
    "    sent_tokens = sent_tokenize(new_text)\n",
    "    return sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf6e5d92-220e-4a1e-91d5-bd6a5c954f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sent = 0\n",
    "sentences = dict()\n",
    "\n",
    "for essay in essays.items():\n",
    "    key = essay[0]\n",
    "    content = essay[1][0]\n",
    "    sents = cleaning(content)\n",
    "    for s in sents:\n",
    "        sent_doc = [s, key]\n",
    "        sentences.update({id_sent : sent_doc})\n",
    "        id_sent += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f89e239-7055-4334-9799-949bf3eae299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce976b8-35f2-4ca8-ad44-c830d461c6b7",
   "metadata": {},
   "source": [
    "Мы создали словарь, в котором ключами являются id предложений. Значения - текст предложения и id сочинения, из которого оно было извлечено. \n",
    "\n",
    "Длина корпуса - 1527 предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e132b4-648b-40f0-8ebb-5eb26c7d84f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' В предложенном для анализа тексте Владимир Николаевич Крупин размышляет о взаимодействии природы и человека.',\n",
       " 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "616f2f08-7633-4e82-b19e-d9aac25183fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus_sent.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(sentences, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a9287-8926-4c42-b2e6-c9d04f242680",
   "metadata": {},
   "source": [
    "# Частеречная разметка корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d9b5e-d5f2-454c-976b-1b4b6847a77b",
   "metadata": {},
   "source": [
    "Для морфологической разметки корпуса было решено использовать библиотеку pymorphy по нескольким причинам:\n",
    "* относительно высокая точноть разметки и производительность\n",
    "* удобный тегсет, специализированный для русского языка\n",
    "* несколько вариантов морфологического разбора с вероятностью каждого -> возможность разрешать или не разрешать морфологическую неоднозначность в особых случаях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22093318-fd6d-46d4-b887-c0a20c538faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "676bf4c6-7ca6-433a-93ac-9a6b25bd2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8dc2b-2e7f-4271-9315-347d8ef8ed2e",
   "metadata": {},
   "source": [
    "**Разрешение морфологической неоднозначности**\n",
    "\n",
    "Было принято решение в отдельных случаях в морфологической разметке приписывать одной и той же словоформе нескольких разборов. К этим случаям относятся ситуации, когда определение части речи зависит от контекста, ср.:\n",
    "* *так* - наречие или частица\n",
    "* формы прилагательных, совпадающие с формой причастий (*открытый* и под.)\n",
    "\n",
    "Pymorphy указывает вероятность того, что тот или иной разбор правильный (score). В случаях, когда score >= 0,6, словоформе приписывает один, наиболее вероятный тег. В остальных случаях словоформе приписывается несколько возможных разборов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f0c8d8-9c2e-4ba9-9313-9407cdb1f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging(word):\n",
    "    parsed = morph.parse(word.lower())\n",
    "    wordform = parsed[0].word\n",
    "    lemma = [parsed[0].normal_form]\n",
    "    pos = [str(parsed[0].tag).split(',')[0].split(' ')[0]]\n",
    "    if parsed[0].score < 0.6:\n",
    "        for option in parsed:\n",
    "            other_tag = str(option.tag).split(',')[0].split(' ')[0]\n",
    "            if other_tag not in pos:\n",
    "                pos.append(other_tag)\n",
    "                lemma.append(option.normal_form)\n",
    "        return wordform, lemma, pos\n",
    "    else:\n",
    "        return wordform, lemma, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52222c7a-f1c3-43d0-847d-f954a316acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dict()\n",
    "token_id = 0\n",
    "\n",
    "for sent in sentences.items():\n",
    "    sent_id = sent[0]\n",
    "    sentence = sent[1][0]\n",
    "    words = word_tokenize(sentence)\n",
    "    for w in words:\n",
    "        word_info = tagging(w)\n",
    "        num_tags = len(word_info[2])\n",
    "        if num_tags > 1:\n",
    "            for i in range(num_tags):\n",
    "                info = {'wordform' : word_info[0],\n",
    "                        'lemma' : word_info[1][i],\n",
    "                        'pos' : word_info[2][i],\n",
    "                        'sent_id' : sent_id}\n",
    "                tokens.update({token_id : info})\n",
    "                token_id += 1\n",
    "        else:\n",
    "            info = {'wordform' : word_info[0],\n",
    "                    'lemma' : word_info[1][0],\n",
    "                    'pos' : word_info[2][0],\n",
    "                    'sent_id' : sent_id}\n",
    "            tokens.update({token_id : info})\n",
    "            token_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3860955-4e01-459c-8b0c-c81134c43fa5",
   "metadata": {},
   "source": [
    "**Корпус токенов**\n",
    "\n",
    "Мы создали словарь, в котором ключами являются token_id. По каждому ключу выдаётся следующая информация о словоформе:\n",
    "\n",
    "* сама словоформа\n",
    "* лемма\n",
    "* pos\n",
    "* id предложения, в котором она содержится\n",
    "\n",
    "В случаях, когда словоформа имеет несколько вариантов разбора, каждый разбор хранится под отедльным token_id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3a4e9-9d36-44c9-8d47-4ec92c7a1726",
   "metadata": {},
   "source": [
    "Словоформа с единственным разбором:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5e472bc-87b0-4f08-bc49-e4de8bc23ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordform': 'в', 'lemma': 'в', 'pos': 'PREP', 'sent_id': 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51fe44-8277-479b-be43-42fb72544696",
   "metadata": {},
   "source": [
    "Словоформа с двумя вариантами разбора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60d8ff58-4f1d-400c-b4e9-2b192617ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wordform': 'следующие', 'lemma': 'следующий', 'pos': 'ADJF', 'sent_id': 1}\n",
      "{'wordform': 'следующие', 'lemma': 'следовать', 'pos': 'PRTF', 'sent_id': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tokens[23])\n",
    "print(tokens[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e886f25-e2ad-43ae-896d-338737d551cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32009"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e224b-d78e-4e34-90b1-2a8569a55e3a",
   "metadata": {},
   "source": [
    "Всего корпус содержит 32009 токенов (включая пунктуацию)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bc367a5-e09a-41b8-aa16-715bf2307b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus_tokens.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(tokens, file, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
